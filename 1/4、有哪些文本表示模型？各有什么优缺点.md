有哪些文本表示模型？各有什么优缺点



文本是一类非常重要的非结构化数据，如何表示文本数据一直是机器学习领域的一个重要研究方向

**词袋模型** 和 **N-gram 模型**

* 词袋模型

  将每篇文章看成一袋子词，忽略词出现的顺序。具体来说，每篇文章可以看出一个长向量，向量中的每一维代表一个单词，维度对应的值反映了这个词在原文章中的重要程度，常使用 TF-IDF 来计算。公式为

  TF-IDF($t$,$d$) = TF($t$,$d$) $\times$IDF($t$)

  其中 TF($t$,$d$) 为单词 $t$ 在文档 $d$ 中出现的频率，IDF($t$) 是逆文档频率。

* N-gram模型

  将连续出现的 **n** 个词（n<<N）组成的词组也作为一个单独的特征放到向量表示中去。例如 natural language processing，作为一个单独的特征，而不是拆分成 natural、language、processing三个词。

**主题模型**

从文本库中发现有代表性的主题，并且能够计算出每篇文章的主题分布

**词嵌入和深度学习模型**

* 词嵌入

  核心思想是，将每个词都映射成低维空间K（通常 K=50~300维）上的一个稠密向量。

* 如果一篇文章有N个词，就可以用 $N\times K$维的矩阵来表示这篇文章。但是这样的表示过于底层，如果直接输入到机器学习模型中，很难得到满意的结果。卷积神经网络和循环神经网络的结构在文本中取得了很好的效果，主要是由于他们能够更好地对文本进行建模，抽取出一些高层的语义特征。与全连接的网络结构相比，他们一方面更好地抓住了文本的特征，另一方面减少了网络中待学习的参数，提高了训练速度，降低了过拟合的风险。